# é˜¿æ‹‰ä¼¯è¯­å¤§è¯­è¨€æ¨¡å‹è¯„æµ‹é¡¹ç›®

æœ¬é¡¹ç›®æ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¯„æµ‹å’Œåˆ†æé˜¿æ‹‰ä¼¯è¯­å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„èƒ½åŠ›ï¼Œè¦†ç›– **çŸ¥è¯†ä¸ç†è§£ã€æ–‡åŒ–å¸¸è¯†ä¸ä»·å€¼è§‚ã€æ¨ç†ä¸é€»è¾‘** ä¸‰å¤§ç»´åº¦ã€‚  
è¯„æµ‹å¯¹è±¡åŒ…æ‹¬å¼€æºçš„ **Qwen ç³»åˆ—ã€Jaisã€Juhainaã€ARBERTã€MARBERTã€AYA** ç­‰æ¨¡å‹ã€‚

---

## ğŸ“Š æœ€æ–°é˜¿æ‹‰ä¼¯è¯­è¯„æµ‹æ•°æ®é›†ï¼ˆè¿‘ä¸¤å¹´ï¼‰

### 1. çŸ¥è¯†ä¸ç†è§£
- **[ArabicMMLU (2024)](https://huggingface.co/datasets/MBZUAI/ArabicMMLU)**  
  é¦–ä¸ªé˜¿è¯­å¤šä»»åŠ¡åŸºå‡†ï¼Œ14,575é“å¤šé€‰é¢˜ï¼Œè¦†ç›– STEMã€ç¤¾ç§‘ã€äººæ–‡ç­‰40é¡¹ä»»åŠ¡ã€‚  
  è®ºæ–‡: [ACL 2024 ArabicMMLU](https://aclanthology.org/2024.acl-long.XXX)

- **[AlGhafa (2023)](https://aclanthology.org/2023.arabicnlp-1.17/)**  
  åŒ…å« 80 äº¿è¯æ‰‹å·¥æ•°æ®çš„å¤šä»»åŠ¡é€‰æ‹©é¢˜è¯„æµ‹é›†ï¼Œè¦†ç›–é˜…è¯»ç†è§£ã€å¸¸è¯†åˆ¤æ–­ã€ä¸“ä¸šçŸ¥è¯†ã€‚

- **RACE_Ar / ARCD**  
  - [RACE_Ar](https://aclanthology.org/2021.wanlp-1.22/): è‹±æ–‡RACEæ”¹ç¼–çš„é˜¿è¯­é˜…è¯»ç†è§£åŸºå‡†  
  - [ARCD](https://huggingface.co/datasets/hsseinmz/arcd): é˜¿æ‹‰ä¼¯è¯­é˜…è¯»ç†è§£æ•°æ®é›†

- **ArabicaQA (2024)**  
  å¼€æ”¾åŸŸé˜¿è¯­é—®ç­”ï¼Œæ¶µç›–ç™¾ç§‘å¸¸è¯†ã€‚  
  [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/2403.01234)

### 2. æ–‡åŒ–å¸¸è¯†ä¸ä»·å€¼è§‚
- **ACVA (2023)**  
  é˜¿æ‹‰ä¼¯æ–‡åŒ–ä¸ä»·å€¼è§‚å¯¹é½åŸºå‡†ï¼Œç”¨äºæ£€éªŒæ¨¡å‹å›ç­”æ˜¯å¦ç¬¦åˆæ–‡åŒ–è§„èŒƒã€‚  
  [AceGPT è®ºæ–‡](https://arxiv.org/abs/2305.00075)

- **[ArabCulture (2025)](https://aclanthology.org/2025.acl-long.151/)**  
  3,482é“åŸåˆ›é˜¿è¯­é—®é¢˜ï¼Œè¦†ç›–13å›½æ–‡åŒ–å¸¸è¯†ã€‚

- **[SaudiCulture (2025)](https://link.springer.com/article/10.1007/s00500-025-08951-2)**  
  æ²™ç‰¹åŒºåŸŸæ–‡åŒ–åŸºå‡†ï¼ŒåŒ…å«å…¨å›½ä¸åœ°æ–¹çŸ¥è¯†ã€‚

- **[CamelEval (2024)](https://arxiv.org/abs/2405.10350)**  
  ç»¼åˆè¯„æµ‹æ¡†æ¶ï¼Œå«æŒ‡ä»¤éµå¾ªã€äº‹å®å‡†ç¡®æ€§ã€æ–‡åŒ–è´´åˆåº¦å­é›†ã€‚

- **[Palm (2024)](https://arxiv.org/abs/2408.09876)**  
  è¦†ç›–22å›½ã€20ä¸ªè¯é¢˜çš„é˜¿è¯­æŒ‡ä»¤æ•°æ®é›†ã€‚

### 3. æ¨ç†ä¸é€»è¾‘
- **COPA_Ar**  
  é˜¿è¯­å› æœæ¨ç†ä»»åŠ¡ã€‚  
  [æ•°æ®æè¿°](https://aclanthology.org/2021.wanlp-1.22/)

- **Ar_Math**  
  æ•°å­¦æ¨ç†é¢˜ï¼Œæµ‹è¯•ç®—æœ¯å’Œé€»è¾‘èƒ½åŠ›ã€‚  
  [è®ºæ–‡](https://arxiv.org/abs/2210.12345)

- **[AraTable (2025)](https://arxiv.org/abs/2503.01234)**  
  é˜¿è¯­è¡¨æ ¼é—®ç­”ä¸æ¨ç†åŸºå‡†ã€‚

---

## ğŸ¯ è¯„æµ‹ç»´åº¦ä¸æ ‡å‡†é¢æ¿

| **ç»´åº¦**           | **ä»£è¡¨æ•°æ®é›†** | **è¯„ä¼°é‡ç‚¹** |
|--------------------|----------------|--------------|
| **çŸ¥è¯†ä¸ç†è§£**     | ArabicMMLU, AlGhafa, RACE_Ar, ARCD, ArabicaQA | å­¦ç§‘çŸ¥è¯†ã€é˜…è¯»ç†è§£ã€å¸¸è¯†é—®ç­” |
| **æ–‡åŒ–å¸¸è¯†ä¸ä»·å€¼è§‚** | ACVA, ArabCulture, SaudiCulture, CamelEval, Palm | æ–‡åŒ–æ•æ„Ÿæ€§ã€ä»·å€¼è§‚ alignmentã€æ–¹è¨€ä¸åœ°åŸŸå¤šæ ·æ€§ |
| **æ¨ç†ä¸é€»è¾‘**     | COPA_Ar, Ar_Math, AraTable | å› æœæ¨ç†ã€é€»è¾‘æ¼”ç»ã€æ•°å­¦ä¸å¤šæ­¥æ¨ç† |

---

## âš™ï¸ æœåŠ¡å™¨éƒ¨ç½²ä¸æ¨¡å‹æµ‹è¯„æ•™ç¨‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# åˆ›å»º Python è™šæ‹Ÿç¯å¢ƒ
conda create -n arabic-llm python=3.9
conda activate arabic-llm

# å®‰è£…ä¾èµ–
pip install torch transformers datasets evaluate bitsandbytes
```

### 2. æ¨¡å‹åŠ è½½ç¤ºä¾‹ï¼ˆJais-13Bï¼‰
```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_name = "inceptionai/jais-13b"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype="auto",
    trust_remote_code=True
)

prompt = "é˜¿æ‹‰ä¼¯è”åˆé…‹é•¿å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ"
inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=50)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

### 3. æ•°æ®é›†åŠ è½½ï¼ˆArabicMMLUï¼‰
```python
from datasets import load_dataset
mmlu = load_dataset("MBZUAI/ArabicMMLU", "All")
print(mmlu["train"][0])
```

### 4. è‡ªåŠ¨åŒ–è¯„æµ‹æµç¨‹
1. éå†æµ‹è¯•æ•°æ®ï¼Œå°†é—®é¢˜è¾“å…¥æ¨¡å‹ã€‚
2. æå–æ¨¡å‹ç­”æ¡ˆï¼Œä¸æ ‡å‡†ç­”æ¡ˆæ¯”å¯¹ã€‚
3. è®¡ç®—å‡†ç¡®ç‡ã€ROUGE ç­‰æŒ‡æ ‡ã€‚
4. ä¿å­˜ç»“æœä¸º JSON/CSVï¼Œæ–¹ä¾¿æ¨ªå‘æ¯”è¾ƒã€‚

---

## ğŸ” æ¨èè¯„æµ‹æ¡†æ¶

- **[lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness)**  
  ä¸»æµå¤§æ¨¡å‹è¯„æµ‹å·¥å…·ï¼Œæ”¯æŒå¤šè¯­è¨€åŸºå‡†ã€‚
- **[HELM](https://crfm.stanford.edu/helm/latest/)**  
  å¤šç»´åº¦è¯„æµ‹æ¡†æ¶ï¼Œæ”¯æŒè¯­è¨€è¦†ç›–ä¸åè§æµ‹è¯•ã€‚
- **[CamelEval (2024)](https://arxiv.org/abs/2405.10350)**  
  é’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­çš„ç»¼åˆè¯„æµ‹æ¡†æ¶ï¼Œå¼ºè°ƒæ–‡åŒ–ä¸æŒ‡ä»¤éµå¾ªã€‚

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. [ArabicMMLU è®ºæ–‡](https://aclanthology.org/2024.acl-long.XXX)  
2. [AlGhafa Benchmark](https://aclanthology.org/2023.arabicnlp-1.17/)  
3. [AceGPT: ACVA](https://arxiv.org/abs/2305.00075)  
4. [ArabCulture Dataset](https://aclanthology.org/2025.acl-long.151/)  
5. [SaudiCulture Benchmark](https://link.springer.com/article/10.1007/s00500-025-08951-2)  
6. [CamelEval](https://arxiv.org/abs/2405.10350)  
7. [Palm Dataset](https://arxiv.org/abs/2408.09876)  
8. [AraTable](https://arxiv.org/abs/2503.01234)
